{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlvgRnzgRauX"
   },
   "source": [
    "todo: \n",
    "- plot loss. see if jumps up \n",
    "- drop out. (may increase interpretability of mid layers?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qg1RGkfrGHO_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from time import perf_counter, time\n",
    "from functools import lru_cache\n",
    "import pickle\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "from IPython import display\n",
    "from imageio import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dfYyPOmxtB4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3h6NjX9OFAOV"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "except ModuleNotFoundError:\n",
    "    ROOT = 'images'\n",
    "else:\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT = '/content/drive/My Drive/Colab Notebooks/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NzRfvSWx5Zs"
   },
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "  def __init__(self, width, depth, n_channels = 3):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.width = width\n",
    "    self.depth = depth\n",
    "    self.n_channels = n_channels\n",
    "    self.myLayers = []\n",
    "    for i in range(depth):\n",
    "      layer = Dense(\n",
    "        width, activation='relu', name = f'relu_layer_{i}', \n",
    "        kernel_initializer=tf.initializers.RandomNormal(\n",
    "          stddev = (width** -.5), \n",
    "        ), \n",
    "        bias_initializer  =tf.initializers.RandomNormal(stddev=0.01),\n",
    "      )\n",
    "      self.myLayers.append(layer)\n",
    "    self.last = Dense(n_channels, activation='sigmoid', name = f'sigmoid_layer')\n",
    "\n",
    "  def call(self, x):\n",
    "    for layer in self.myLayers:\n",
    "      x = layer(x)\n",
    "    return self.last(x)\n",
    "  \n",
    "  def build(self, shape = (None, 2)):\n",
    "    super().build(shape)\n",
    "\n",
    "  def copy(self):\n",
    "    model = MyModel(self.width, self.depth, self.n_channels)\n",
    "    model.build()\n",
    "    model.set_weights(self.get_weights())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vaOyyo8rx7NS"
   },
   "outputs": [],
   "source": [
    "@lru_cache()\n",
    "def getRaster(width, height):\n",
    "  buffer = np.zeros((width*height, 2))\n",
    "  x_lin_space = np.linspace(-1, 1, width)\n",
    "  y_lin_space = np.linspace(-1, 1, height)\n",
    "  for x in range(width):\n",
    "    for y in range(height):\n",
    "      buffer[x * height + y, :] = (x_lin_space[x], y_lin_space[y])\n",
    "  return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSOnkf9xx8Q9"
   },
   "outputs": [],
   "source": [
    "def view(model, width, height, view_h = 5):\n",
    "    output = model.predict(getRaster(width, height))\n",
    "    plt.imshow(\n",
    "        np.reshape(output, (width, height, model.n_channels)), \n",
    "        vmin=0, vmax=1, \n",
    "    )\n",
    "    plt.axis('off')\n",
    "    plt.gcf().set_size_inches(view_h / height * width, view_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7woFIMfx9ir"
   },
   "outputs": [],
   "source": [
    "def viewInitField():\n",
    "    model = MyModel(4, 4, 3)\n",
    "    model.build()\n",
    "    model.summary()\n",
    "    view(model)\n",
    "# viewInitField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLuD-XQ5IAXB"
   },
   "outputs": [],
   "source": [
    "os.chdir(ROOT)\n",
    "img_names = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWIUfuF1Frd2"
   },
   "outputs": [],
   "source": [
    "def loadData(img_name, resolution = 50, to_gray = False):\n",
    "  img = imread(img_name) / 255\n",
    "  width, height = img.shape[:2]\n",
    "  try:\n",
    "    if img.shape[2] == 4:\n",
    "      img = img[:, :, :3]\n",
    "    elif img.shape[2] == 1:\n",
    "      raise IndexError\n",
    "    else:\n",
    "      assert img.shape[2] == 3\n",
    "  except IndexError:\n",
    "    t = np.zeros((width, height, 3))\n",
    "    t[:, :, 0] = img\n",
    "    t[:, :, 1] = img\n",
    "    t[:, :, 2] = img\n",
    "    img = t\n",
    "  zoom_k = resolution / (width * height) ** .5\n",
    "  tt = zoom(img[:, :, 0], zoom_k, order=1)\n",
    "  width, height = tt.shape\n",
    "  t = np.zeros((width, height, 3))\n",
    "  t[:, :, 0] = tt\n",
    "  t[:, :, 1] = zoom(img[:, :, 1], zoom_k, order=1)\n",
    "  t[:, :, 2] = zoom(img[:, :, 2], zoom_k, order=1)\n",
    "  img = t\n",
    "  if to_gray:\n",
    "    img[:, :, 0] = np.mean(img, axis=2)\n",
    "    n_channels = 1\n",
    "  else:\n",
    "    n_channels = 3\n",
    "  x = getRaster(width, height)\n",
    "  y = np.zeros((width * height, n_channels))\n",
    "  for i in range(n_channels):\n",
    "    y[:, i] = np.reshape(img[:, :, i], (width * height, ))\n",
    "  return x, y, width, height, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0K2Xd3dgK_5C"
   },
   "outputs": [],
   "source": [
    "previewIter = iter(img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlvAYgTvLM6K"
   },
   "outputs": [],
   "source": [
    "# Run this cell multiple times to preview all data. \n",
    "try:\n",
    "  name = next(previewIter)\n",
    "except StopIteration:\n",
    "  print(\"No more.\")\n",
    "else:\n",
    "  x, y, w, h, img = loadData(name, 150)\n",
    "  print(name)\n",
    "  plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyCallback(tf.keras.callbacks.Callback):\n",
    "#     def __init__(self, width, height):\n",
    "#         super().__init__()\n",
    "#         self.width = width\n",
    "#         self.height = height\n",
    "#     def on_epoch_begin(self, epoch, logs=None):\n",
    "#         print(epoch)\n",
    "#         sleep(1)\n",
    "#         view(model, self.width, self.height, 5)\n",
    "#         display.clear_output(wait=True)\n",
    "#         display.display(plt.gcf())\n",
    "# #         sleep(.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXUsTTFaPzWW"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    img_name, is_gray = False, SPF = 1.5, steps_per_epoch = 32, \n",
    "    canvas_size = (12, 5), \n",
    "    resolution = [150], \n",
    "    nn_width = [64], nn_depth = [3], \n",
    "    loss = [tf.keras.losses.mean_squared_error], \n",
    "):\n",
    "    shape = []\n",
    "    titles = []\n",
    "    if len(resolution) > 1:\n",
    "        shape.append(len(resolution))\n",
    "        titles.append(('resolution', resolution))\n",
    "    if len(nn_width) > 1:\n",
    "        shape.append(len(nn_width))\n",
    "        titles.append(('NN width', nn_width))\n",
    "    if len(nn_depth) > 1:\n",
    "        shape.append(len(nn_depth))\n",
    "        titles.append(('NN depth', nn_depth))\n",
    "    if len(loss) > 1:\n",
    "        shape.append(len(loss))\n",
    "        titles.append(('loss', ['L2' if x is tf.keras.losses.mean_squared_error else 'L1' for x in loss]))\n",
    "    if len(shape) != 2:\n",
    "        raise Exception('comparison limited to 2D, sorry')\n",
    "    fig, axes = plt.subplots(*shape)\n",
    "#     try:\n",
    "#         iter(axes)\n",
    "#     except TypeError:\n",
    "#         axes = [axes]\n",
    "    for i, ax in enumerate(axes[0, :]):\n",
    "        ax.set_title(titles[1][0] + ' = ' + str(titles[1][1][i]))\n",
    "    for i, ax in enumerate(axes[:, 0]):\n",
    "        ax.set_ylabel(titles[0][0] + ' = ' + str(titles[0][1][i]))\n",
    "    flat_axes = [x for t in axes for x in t]\n",
    "    for ax in flat_axes:\n",
    "        ax.tick_params(\n",
    "            axis='both', which='both', \n",
    "            bottom=False, top=False, \n",
    "            labelbottom=False, \n",
    "            right=False, left=False, \n",
    "            labelleft=False, \n",
    "        )\n",
    "    iterAxes = iter(flat_axes)\n",
    "    max_w = 0\n",
    "    max_h = 0\n",
    "    for r in resolution:\n",
    "        x, y, w, h, _ = loadData(img_name, r, is_gray)\n",
    "        if w > max_w:\n",
    "            max_w = w\n",
    "            max_h = h\n",
    "        for nw in nn_width:\n",
    "            for nd in nn_depth:\n",
    "                for l in loss:\n",
    "                    model = MyModel(nw, nd, 1 if is_gray else 3)\n",
    "                    model.compile(\n",
    "                        optimizer='adam',\n",
    "                        loss=l,\n",
    "                    )\n",
    "                    setups.append((model, x, y, w, h, next(iterAxes)))\n",
    "    age = np.zeros((len(setups), ))\n",
    "    epoch = np.zeros((len(setups), ), dtype=np.int32)\n",
    "    next_render = 0\n",
    "    render_i = 0\n",
    "    while True:\n",
    "        if next_render < np.sum(age):\n",
    "            start = time()\n",
    "            for model, x, y, w, h, ax in setups:\n",
    "                output = model.predict(getRaster(max_w, max_h))\n",
    "                ax.imshow(\n",
    "                    np.reshape(output, (max_w, max_h, model.n_channels)), \n",
    "                    vmin=0, vmax=1, \n",
    "                )\n",
    "            fig.set_size_inches(*canvas_size)\n",
    "            fig.tight_layout()\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(fig)\n",
    "            next_render += SPF\n",
    "            plt.savefig(f'../frames/{render_i}.jpg')\n",
    "            render_i += 1\n",
    "            print('Render overhead:', format((time() - start) / SPF, '.1%'))\n",
    "            print('Epochs:')\n",
    "            print(np.reshape(epoch, shape))\n",
    "            model, x, y, w, h, ax = setups[-1]\n",
    "            losses.append(model.evaluate(\n",
    "                x, y, \n",
    "                batch_size = w * h, \n",
    "                steps = 1, \n",
    "                verbose = 0, \n",
    "            ))\n",
    "            print('loss:', *losses[-5:], sep='\\n')\n",
    "        elected = np.argmin(age)\n",
    "        model, x, y, w, h, ax = setups[elected]\n",
    "        start = time()\n",
    "        model.fit(\n",
    "            x, y, \n",
    "            steps_per_epoch = steps_per_epoch, \n",
    "            epochs = 1, \n",
    "            verbose = 0, \n",
    "            batch_size = w * h, \n",
    "        )\n",
    "        age[elected] += time() - start\n",
    "        epoch[elected] += 1\n",
    "    display.clear_output(wait=True)\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvK6NxDjSe7s",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "setups = []\n",
    "losses = []\n",
    "\n",
    "train(\n",
    "    'polyak et al.png', \n",
    "    is_gray = False, \n",
    "    SPF = 40, \n",
    "    canvas_size = (7, 5), \n",
    "    steps_per_epoch = 1, \n",
    "    resolution = [300, 300], \n",
    "    nn_width = [128, 128], \n",
    "    nn_depth = [6], \n",
    "#     nn_depth = [4, 8], \n",
    "#     loss = [tf.keras.losses.mean_squared_error, tf.keras.losses.mean_absolute_error], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../losses', losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect(model, resolution = 150):\n",
    "    activations = []\n",
    "    activations.append(getRaster(resolution, resolution))\n",
    "    for reluLayer in model.myLayers:\n",
    "        activations.append(reluLayer(activations[-1]))\n",
    "    activations.append(model.last(activations[-1]))\n",
    "    fig, axes = plt.subplots(model.depth + 2, model.width)\n",
    "    def draw(i, j, field, absolute = False):\n",
    "        axes[i, j].imshow(\n",
    "            np.reshape(field, (resolution, resolution)), \n",
    "            **({\"vmin\": 0, \"vmax\": 1} if absolute else {})\n",
    "        )\n",
    "        axes[i, j].axis('off')\n",
    "    mid_col = model.width // 2\n",
    "    draw(0, mid_col,     activations[0][:, 0])\n",
    "    draw(0, mid_col + 1, activations[0][:, 1])\n",
    "    for i in range(model.depth + 2):\n",
    "        for j in range(model.width):\n",
    "            if i in (0, model.depth + 1):\n",
    "                axes[i, j].axis('off')\n",
    "                continue\n",
    "            draw(i, j, activations[i][:, j])\n",
    "    for c in range(model.n_channels):\n",
    "        draw(\n",
    "            model.depth + 1, mid_col + c, \n",
    "            activations[model.depth + 1][:, c], absolute = True, \n",
    "        )\n",
    "    fig.set_size_inches(model.width * 2, (model.depth + 2) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect(cModels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why does losses go up? \n",
    "1st experiment. Is `fit` deterministic? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h, _ = loadData('polyak et al.png', 300, False)\n",
    "model = MyModel(128, 6, 3)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.mean_squared_error,\n",
    ")\n",
    "model.fit(\n",
    "    x, y, \n",
    "    steps_per_epoch = 1, \n",
    "    epochs = 1, \n",
    "#     verbose = 0, \n",
    "    batch_size = w * h, \n",
    ")\n",
    "model_copy = model.copy()\n",
    "model.evaluate(\n",
    "    x, y, \n",
    "    batch_size = w * h, \n",
    "    steps = 1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple times\n",
    "\n",
    "model = model_copy\n",
    "model_copy = model.copy()\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss=tf.keras.losses.mean_squared_error,\n",
    ")\n",
    "model.fit(\n",
    "    x, y, \n",
    "    steps_per_epoch = 1, \n",
    "    epochs = 1, \n",
    "#     verbose = 0, \n",
    "    batch_size = w * h, \n",
    ")\n",
    "model.evaluate(\n",
    "    x, y, \n",
    "    batch_size = w * h, \n",
    "    steps = 1, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. So they prolly need ideas from Blind Descend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrutchGDScheduler:\n",
    "    def __init__(self, acceleration = 1.1, verbose = True):\n",
    "        self.lr = None\n",
    "        self.acceleration = acceleration\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __call__(self, epoch, lr):\n",
    "        if self.lr is None:\n",
    "            self.lr = lr\n",
    "            if self.verbose:\n",
    "                print('Initial learning rate:', lr)\n",
    "        print('learning rate adjustment:', self.lr / lr)\n",
    "        return self.lr\n",
    "    \n",
    "    def succeed(self):\n",
    "        self.lr *= self.acceleration\n",
    "    \n",
    "    def fail(self):\n",
    "        self.lr *= .618\n",
    "\n",
    "def crutchGD(model, x, y, w, h, lossFunc):\n",
    "    sched = CrutchGDScheduler()\n",
    "    callbacks = tf.keras.callbacks.LearningRateScheduler(sched)\n",
    "    model.compile(\n",
    "        optimizer='sgd',\n",
    "        loss=lossFunc,\n",
    "    )\n",
    "    loss = np.inf\n",
    "    while True:\n",
    "        model_copy = model.copy()\n",
    "        model.fit(\n",
    "            x, y, \n",
    "            steps_per_epoch = 1, \n",
    "            epochs = 1, \n",
    "            verbose = 0, \n",
    "            batch_size = w * h, \n",
    "            callbacks = callbacks, \n",
    "        )\n",
    "        new_loss = model.evaluate(\n",
    "            x, y, \n",
    "            steps = 1, \n",
    "            verbose = 0, \n",
    "            batch_size = w * h, \n",
    "        )\n",
    "        if loss < new_loss:\n",
    "            model = model_copy\n",
    "            model.compile(\n",
    "                optimizer='sgd',\n",
    "                loss=lossFunc,\n",
    "            )\n",
    "            sched.fail()\n",
    "        else:\n",
    "            loss = new_loss\n",
    "            sched.succeed()\n",
    "        yield model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam(model, x, y, w, h, lossFunc, steps_per_epoch):\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=lossFunc,\n",
    "    )\n",
    "    while True:\n",
    "        model.fit(\n",
    "            x, y, \n",
    "            steps_per_epoch = steps_per_epoch, \n",
    "            epochs = 1, \n",
    "            verbose = 0, \n",
    "        )\n",
    "        yield model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADAM = 'ADAM'\n",
    "CRUTCH = 'CRUTCH'\n",
    "\n",
    "def testCrutch(\n",
    "    img_names, crutch_epoch = 3000, \n",
    "    is_gray = False, SPF = 1.5, steps_per_epoch = 32, \n",
    "    canvas_size = (10, 7), \n",
    "    resolution = 150, \n",
    "    nn_width = 64, nn_depth = 6, \n",
    "    lossFunc = tf.keras.losses.mean_squared_error, \n",
    "):\n",
    "    fig, axes = plt.subplots(3, len(img_names))\n",
    "    flat_axes = [x for t in axes for x in t]\n",
    "    for ax in flat_axes:\n",
    "        ax.tick_params(\n",
    "            axis='both', which='both', \n",
    "            bottom=False, top=False, \n",
    "            labelbottom=False, \n",
    "            right=False, left=False, \n",
    "            labelleft=False, \n",
    "        )\n",
    "    ground_truth = [\n",
    "        loadData(img_name, resolution, is_gray) \n",
    "        for img_name in img_names\n",
    "    ]\n",
    "    models = [\n",
    "        MyModel(nn_width, nn_depth, 1 if is_gray else 3) \n",
    "        for _ in img_names\n",
    "    ]\n",
    "\n",
    "    age = np.zeros((2, len(img_names)))\n",
    "    epoch = np.zeros((2, len(img_names)), dtype=np.int32)\n",
    "    next_render = 0\n",
    "    render_i = 0\n",
    "\n",
    "    phase = ADAM\n",
    "    axes[0, 0].set_ylabel(ADAM)\n",
    "    axes[1, 0].set_ylabel(ADAM)\n",
    "    losses = [[[[], []] for _ in img_names] for _ in range(2)]\n",
    "    trainers = [\n",
    "        adam(model, x, y, w, h, lossFunc, steps_per_epoch)\n",
    "        for model, (x, y, w, h, _) in zip(models, ground_truth)\n",
    "    ]\n",
    "    cModels = None\n",
    "    try:\n",
    "        while True:\n",
    "            if phase is ADAM and np.min(epoch[0, :]) >= crutch_epoch:\n",
    "                phase = CRUTCH\n",
    "                cModels = [m.copy() for m in models]\n",
    "                age[1, :] = age[0, :]\n",
    "                axes[1, 0].set_ylabel(CRUTCH)\n",
    "                cTrainers = [\n",
    "                    crutchGD(model, x, y, w, h, lossFunc)\n",
    "                    for model, (x, y, w, h, _) in zip(cModels, ground_truth)\n",
    "                ]\n",
    "            if next_render <= np.sum(age):\n",
    "                next_render += SPF\n",
    "                start = time()\n",
    "                for i, (x, y, w, h, _) in enumerate(ground_truth):\n",
    "                    if epoch[0, i] == 0:\n",
    "                        continue\n",
    "                    output = models[i].predict(getRaster(w, h))\n",
    "                    reshaped = np.reshape(output, (w, h, model.n_channels))\n",
    "                    axes[0, i].clear()\n",
    "                    axes[0, i].imshow(reshaped, vmin=0, vmax=1)\n",
    "                    if phase is CRUTCH:\n",
    "                        if epoch[1, i] == 0:\n",
    "                            continue\n",
    "                        output = cModels[i].predict(getRaster(w, h))\n",
    "                        reshaped = np.reshape(output, (w, h, model.n_channels))\n",
    "                    axes[1, i].clear()\n",
    "                    axes[1, i].imshow(reshaped, vmin=0, vmax=1)\n",
    "                render_overhead = format((time() - start) / SPF, '.1%')\n",
    "                start = time()\n",
    "                for i, (x, y, w, h, _) in enumerate(ground_truth):\n",
    "                    if epoch[0, i] == 0:\n",
    "                        continue\n",
    "                    loss_val = models[i].evaluate(\n",
    "                        x, y, \n",
    "                        batch_size = w * h, \n",
    "                        steps = 1, \n",
    "                        verbose = 0, \n",
    "                    )\n",
    "                    losses[0][i][0].append(render_i)\n",
    "                    losses[0][i][1].append(loss_val)\n",
    "                    if phase is CRUTCH:\n",
    "                        if epoch[1, i] == 0:\n",
    "                            continue\n",
    "                        loss_val = cModels[i].evaluate(\n",
    "                            x, y, \n",
    "                            batch_size = w * h, \n",
    "                            steps = 1, \n",
    "                            verbose = 0, \n",
    "                        )\n",
    "                        losses[1][i][0].append(render_i)\n",
    "                        losses[1][i][1].append(loss_val)\n",
    "                eval_overhead = format((time() - start) / SPF, '.1%')\n",
    "                start = time()\n",
    "                for i, (x, y, w, h, _) in enumerate(ground_truth):\n",
    "                    axes[2, i].clear()\n",
    "                    axes[2, i].plot(losses[0][i][0], losses[0][i][1], label=ADAM)\n",
    "                    axes[2, i].plot(losses[1][i][0], losses[1][i][1], label=CRUTCH)\n",
    "                axes[2, -1].legend()\n",
    "                axes[0, 0].set_ylabel(ADAM)\n",
    "                axes[1, 0].set_ylabel(phase)\n",
    "                axes[2, 0].set_ylabel('loss')\n",
    "                pltLoss_overhead = format((time() - start) / SPF, '.1%')\n",
    "                start = time()\n",
    "                fig.set_size_inches(*canvas_size)\n",
    "                fig.tight_layout()\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(fig)\n",
    "                print('Render overhead:', render_overhead)\n",
    "                print('Evaluation overhead:', eval_overhead)\n",
    "                print('plot loss overhead:', pltLoss_overhead)\n",
    "                print('redraw overhead:', format((time() - start) / SPF, '.1%'))\n",
    "                start = time()\n",
    "                plt.savefig(f'../frames/{render_i}.jpg')\n",
    "                print('save fig overhead:', format((time() - start) / SPF, '.1%'))\n",
    "                render_i += 1\n",
    "                print('Epochs (the two rows are not comparable):')\n",
    "                print(epoch)\n",
    "            if phase is ADAM:\n",
    "                col = age[0, :].argmin()\n",
    "                row = 0\n",
    "            else:\n",
    "                row, col = np.unravel_index(age.argmin(), age.shape)\n",
    "            start = time()\n",
    "            if row == 0:\n",
    "                models[col] = next(trainers[col])\n",
    "            else:\n",
    "                cModels[col], _ = next(cTrainers[col])\n",
    "            age[row, col] += time() - start\n",
    "            epoch[row, col] += 1\n",
    "    except KeyboardInterrupt:\n",
    "        return models, cModels, ground_truth, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models, cModels, ground_truth, losses = testCrutch(\n",
    "    ['sinGAN_2.png', 'sinGAN_1.jpg', 'shoob_3.jpg'], \n",
    "    crutch_epoch = 30000, \n",
    "    nn_width = 64, \n",
    "    canvas_size = (10 * .7, 7 * .7), SPF = 20, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../archive/ground_truth_losses.pickle', 'wb') as f:\n",
    "    pickle.dump([ground_truth, losses], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[2].save('../archive/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../archive/crutch_compare/ground_truth_losses.pickle', 'rb') as f:\n",
    "    ground_truth_demo, losses_demo = pickle.load(f)\n",
    "\n",
    "START = 20\n",
    "_START = 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "for i, (x, y, w, h, _) in enumerate(ground_truth_demo):\n",
    "    axes[i].plot(losses_demo[0][i][0][START:], losses_demo[0][i][1][START:], label=ADAM)\n",
    "    axes[i].plot(losses_demo[1][i][0][_START:], losses_demo[1][i][1][_START:], label=CRUTCH)\n",
    "axes[-1].legend()\n",
    "fig.set_size_inches(10, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. it's also cheap to evaluate on the whole training set. Compare with RejectionAdam? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejectableAdam(\n",
    "    model, x, y, w, h, lossFunc, steps_per_epoch, epochs_per_eval, \n",
    "    crutchAsCure = False, \n",
    "):\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=lossFunc,\n",
    "    )\n",
    "    loss = np.inf\n",
    "    while True:\n",
    "        model_copy = model.copy()\n",
    "        start = perf_counter()\n",
    "        for _ in range(epochs_per_eval):\n",
    "            model.fit(\n",
    "                x, y, \n",
    "                steps_per_epoch = steps_per_epoch, \n",
    "                epochs = 1, \n",
    "                verbose = 0, \n",
    "            )\n",
    "        fit_time = perf_counter() - start\n",
    "        start = perf_counter()\n",
    "        new_loss = model.evaluate(\n",
    "            x, y, \n",
    "            steps = 1, \n",
    "            verbose = 0, \n",
    "            batch_size = w * h, \n",
    "        )\n",
    "        eval_time = perf_counter() - start\n",
    "        if loss < new_loss:\n",
    "            model = model_copy\n",
    "            if crutchAsCure:\n",
    "                sched = CrutchGDScheduler(verbose = False)\n",
    "                callbacks = tf.keras.callbacks.LearningRateScheduler(sched)\n",
    "                model.compile(\n",
    "                    optimizer='sgd',\n",
    "                    loss=lossFunc,\n",
    "                )\n",
    "                while True:\n",
    "                    model_copy = model.copy()\n",
    "                    model.fit(\n",
    "                        x, y, \n",
    "                        steps_per_epoch = 1, \n",
    "                        epochs = 1, \n",
    "                        verbose = 0, \n",
    "                        batch_size = w * h, \n",
    "                        callbacks = callbacks, \n",
    "                    )\n",
    "                    new_loss = model.evaluate(\n",
    "                        x, y, \n",
    "                        steps = 1, \n",
    "                        verbose = 0, \n",
    "                        batch_size = w * h, \n",
    "                    )\n",
    "                    if loss < new_loss:\n",
    "                        model = model_copy\n",
    "                        model.compile(\n",
    "                            optimizer='sgd',\n",
    "                            loss=lossFunc,\n",
    "                        )\n",
    "                        sched.fail()\n",
    "                    else:\n",
    "                        break\n",
    "            model.compile(\n",
    "                optimizer='sgd',\n",
    "                loss=lossFunc,\n",
    "            )\n",
    "        else:\n",
    "            loss = new_loss\n",
    "#         print('IN-TRAIN eval overhead:', eval_time / fit_time)\n",
    "        yield model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testRejectables(\n",
    "    img_names, \n",
    "    is_gray = False, SPF = 1.5, steps_per_epoch = 32, \n",
    "    canvas_size = (10, 7), \n",
    "    resolution = 150, \n",
    "    nn_width = 64, nn_depth = 6, \n",
    "    lossFunc = tf.keras.losses.mean_squared_error, \n",
    "    epochs_per_eval = 1, \n",
    "):\n",
    "    fig, axes = plt.subplots(3, len(img_names))\n",
    "    flat_axes = [x for t in axes for x in t]\n",
    "    for ax in flat_axes:\n",
    "        ax.tick_params(\n",
    "            axis='both', which='both', \n",
    "            bottom=False, top=False, \n",
    "            labelbottom=False, \n",
    "            right=False, left=False, \n",
    "            labelleft=False, \n",
    "        )\n",
    "    ground_truth = [\n",
    "        loadData(img_name, resolution, is_gray) \n",
    "        for img_name in img_names\n",
    "    ]\n",
    "    models = [[], []]\n",
    "    for _ in img_names:\n",
    "        model = MyModel(nn_width, nn_depth, 1 if is_gray else 3)\n",
    "        model.build()\n",
    "        models[0].append(model)\n",
    "        models[1].append(model.copy())\n",
    "\n",
    "    age = np.zeros((2, len(img_names)))\n",
    "    epoch = np.zeros((2, len(img_names)), dtype=np.int32)\n",
    "    next_render = 0\n",
    "    render_i = 0\n",
    "\n",
    "    losses = [[[[], []] for _ in img_names] for _ in range(2)]\n",
    "    trainers = [[], []]\n",
    "    for row, clutch_as_cure in enumerate((False, True)):\n",
    "        for col, (x, y, w, h, _) in enumerate(ground_truth):\n",
    "            trainers[row].append(rejectableAdam(\n",
    "                models[row][col], x, y, w, h, lossFunc, \n",
    "                steps_per_epoch, epochs_per_eval, \n",
    "                clutch_as_cure, \n",
    "            ))\n",
    "    try:\n",
    "        while True:\n",
    "            if next_render <= np.sum(age):\n",
    "                next_render += SPF\n",
    "                start = perf_counter()\n",
    "                for col, (x, y, w, h, _) in enumerate(ground_truth):\n",
    "                    for row in (0, 1):\n",
    "                        if epoch[row, col] == 0:\n",
    "                            continue\n",
    "                        model = models[row][col]\n",
    "                        output = model.predict(getRaster(w, h))\n",
    "                        reshaped = np.reshape(output, (w, h, model.n_channels))\n",
    "                        axes[row, col].clear()\n",
    "                        axes[row, col].imshow(reshaped, vmin=0, vmax=1)\n",
    "                render_overhead = format((perf_counter() - start) / SPF, '.1%')\n",
    "                start = perf_counter()\n",
    "                for row in (0, 1):\n",
    "                    for col, (x, y, w, h, _) in enumerate(ground_truth):\n",
    "                        if epoch[row, col] == 0:\n",
    "                            continue\n",
    "                        loss_val = models[row][col].evaluate(\n",
    "                            x, y, \n",
    "                            batch_size = w * h, \n",
    "                            steps = 1, \n",
    "                            verbose = 0, \n",
    "                        )\n",
    "                        losses[row][col][0].append(render_i)\n",
    "                        losses[row][col][1].append(loss_val)\n",
    "                eval_overhead = format((perf_counter() - start) / SPF, '.1%')\n",
    "                start = perf_counter()\n",
    "                for col, (x, y, w, h, _) in enumerate(ground_truth):\n",
    "                    axes[-1, col].clear()\n",
    "                    for row, label in enumerate(['RejAdam', 'Crutch']):\n",
    "                        axes[-1, col].plot(losses[row][col][0], losses[row][col][1], label=label)\n",
    "                axes[-1, -1].legend()\n",
    "                axes[0, 0].set_ylabel('RejAdam')\n",
    "                axes[1, 0].set_ylabel('Crutch')\n",
    "                axes[2, 0].set_ylabel('loss')\n",
    "                pltLoss_overhead = format((perf_counter() - start) / SPF, '.1%')\n",
    "                start = perf_counter()\n",
    "                fig.set_size_inches(*canvas_size)\n",
    "                fig.tight_layout()\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(fig)\n",
    "                print('Render overhead:', render_overhead)\n",
    "                print('Evaluation overhead:', eval_overhead)\n",
    "                print('plot loss overhead:', pltLoss_overhead)\n",
    "                print('redraw overhead:', format((perf_counter() - start) / SPF, '.1%'))\n",
    "                start = perf_counter()\n",
    "                plt.savefig(f'../frames/{render_i}.jpg')\n",
    "                print('save fig overhead:', format((perf_counter() - start) / SPF, '.1%'))\n",
    "                render_i += 1\n",
    "                print('Epochs (the two rows are not comparable):')\n",
    "                print(epoch)\n",
    "            row, col = np.unravel_index(age.argmin(), age.shape)\n",
    "            start = perf_counter()\n",
    "            models[row][col], _ = next(trainers[row][col])\n",
    "            age[row, col] += perf_counter() - start\n",
    "            epoch[row, col] += 1\n",
    "    except KeyboardInterrupt:\n",
    "        return models, ground_truth, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, ground_truth, losses = testRejectables(\n",
    "    ['sinGAN_2.png', 'sinGAN_1.jpg', 'shoob_3.jpg'], \n",
    "    nn_width = 64, \n",
    "    canvas_size = (10 * .7, 7 * .7), SPF = 20, \n",
    "    steps_per_epoch = 128, epochs_per_eval = 8, \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "insideNeuralImplicitField.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
